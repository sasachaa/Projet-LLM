VIP Cheatsheet: Tips and Tricks Afshine AMIDI and Shervine AMIDI November 26, 2018 Data processing 0 Data augmentation Deep learning models usually need a lot of data to be properly trained. It is often useful to get more data from the existing ones using data augmentation techniques. The main ones are summed up in the table below. More precisely, given the following input image, here are the techniques that we can apply: Original Flip Rotation Random crop Random focus Flipped with respect Rotation with on one part of Image without to an axis for which a slight angle the image modification the meaning of the Simulates incorrect Several random any image is preserved horizon calibration crops can be done in a row Color shift Noise addition Information loss Contrast change Nuances of RGB Addition of noise Parts of image Luminosity changes is slightly changed More tolerance to ignored Controls difference Captures noise quality variation of Mimics potenti cial in exposition due that can occur with light inputs loss of parts of image to time of day exposure D Batch normalization It is a step of hyperparameter 7, B that normalizes the batch (xi). By noting HB,OB the mean and variance of that we want to correct to the batch, it is done as follows:

Ii HB Ti  Y B VoB +6 It is usually done after a fully comected/comolutional layer and before a non-linearity layer and aims at allowing higher learning rates and reducing the strong dependence on initialization. Training a neural network L Epoch In the context of training a model, epoch is a term used to refer to one iteration where the model sees the whole training set to update its weights. D Mini-batch gradient descent During the training phase, updating weights is usually not based on the whole training set at once due to computation complexities or one data point due to noise issues. Instead, the update step is done on mini-batches, where the number of data points in a batch is a hyperparameter that we can tune. J Loss function In order to quantify how a given model performs, the loss function L is usually used to evaluate to what extent the actual outputs y are correctly predicted by the model outputs 2. D Cross-entropy loss In the context of binary classification in neural networks, the cross entropy loss L(z,y) is commonly used and is defined as follows: L(z,u) = ylog(=) + (1 V) log(1 ) D Backpropagation Backpropagation isa method to update the weights in the neural network by taking into account the actual output and the desired output. The derivative with respect to each weight w is computed using the chain rule. OL Of(r) OL Of(a) Or Of(r) t I f(x) Using this method, each weight is updated with the rule: OL(2,) w a Ow a Updating weights In a neural network, weights are updated as follows: Step 1: Take a batch of training data and perform forward propagation to compute the loss. Step 2: Backpropagate the loss to get the gradient of the loss with respect to each weight. Step 3: Use the gradients to update the weights of the network.

Forward propagation Backpropagation Weights update Parameter tuning OXavier initializat ion Instead of initializing the weights in a purely random manner, Xavier initialization enables to have initial weights that take into account characteristics that are unique to the architecture. Transfer learning Training a deep learning model requires a lot of data and more importantly a lot of time. It is often useful to take advantage of pre-trained weights on huge datasets that took days/weeks to train, and leverage it towards our use case. Depending on how much data we have at hand, here are the different ways to leverage this: Training size Illustration Explanation Freezes all layers, Small trains weights on softmax Freezes most layers, Medium trains weights on last layers and softmax Trains weights on layers Large and softmax by initializing weights on pre-trained ones OLearning rate The learning rate, often noted a or sometimes 7, indicates at which pace the weights get updated. It can be fixed or adaptively changed. The current most popular method is called Adam, which is a method that adapts the learning rate. a Adaptive learning rates Letting the learning rate vary when training a model can reduce the training time and improve the numerical optimal solution. While Adam optimizer is the most commonly used technique, others can also be useful. They are summed up in the table below:

Method Explanation Update of a Update of b Dampens oscillations Momentum Improvement to SGD w aUdw b  OUdb 21 parameters to tune Root Mean Square propagation dw db RMSprop Speeds up learning algorithm w a b 4 b a by controlling oscillations VSdw VSdb Adaptive Moment estimation Adam Most popular method w a Udw b 4 b a Udb 4 parameters to tune VSdw + E VSdb + E Remark: other methods include Adadelta, Adagrad and SGD. Regularization 0 Dropout Dropout is a technique used in neural networks to prevent overfitting the training data by dropping out neurons with probability p > 0. It forces the model to avoid relying too much on particular sets of features. Remark: most deep learning frameworks parametrize dropout through the'keep'parameter 1-p. 0 Weight regularization In order to make sure that the weights are not too large and that the model is not overfitting the training set, regularization techniques are usually performed on the model weights. The main ones are summed up in the table below: LASSO Ridge Elastic Net Shrinks coefficients to 0 Tradeoff between variable Makes coefficients smaller Good for variable selection selection and small coefficients 4 8" llell <1 llella <1 (1 -a)lielle ollel <1 +. Alelli +. AOll3 (1 a)llelli + al1013 A R AE R AEI R,a [0,1]

D Early stopping This regularization technique stops the training process as soon as the validation loss reaches a plateau or starts to increase. Error] Validation X Training early stopping Epochs Good practices J Overfitting small batch When debugging a model, it is often useful to make quick tests tos see if there is any major issue with the architecture of the model itself. In particular, in order to make sure that the model can be properly trained, a mini-batch is passed inside the network to see if it can overfit on it. Ifit cannot, it means that the model is either too complex or not complex enough to even overfit on a small batch, let alone a normal-sized training set. a Gradient checking Gradient checking is a method used during the implementation of the backward pass of a neural network. It compares the value of the analytical gradient to the numerical gradient at given points and plays the role of a sanity-check for correctness. Numerical gradient Analytical gradient f(x +h)  f(a h) df Formula (x) a (2) = f'(a) dx 2h dx Expensive; loss has to be computed two times per dimension Exact'result Used to verify correctness Comments of analytical implementation Direct computation -Trade-off in choosing h not too small (numerical instability) Used in the final implementation nor too large (poor gradient approx.)