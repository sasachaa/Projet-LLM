Les chats ont une démarche bien particulière, élégante et silencieuse. Ils marchent sur la pointe des pieds, ce qu’on appelle une démarche digitigrade. Cela signifie qu’ils ne posent pas tout le pied au sol comme nous, mais uniquement les doigts. C’est pour cela que leurs mouvements sont si fluides et discrets.

Quand un chat avance, il déplace ses pattes d’une manière très précise : il pose d’abord une patte arrière, puis la patte avant du même côté vient se placer exactement à l’endroit où était la patte arrière. Ensuite, il fait la même chose de l’autre côté. Cela lui permet de se déplacer sans bruit et avec beaucoup d’équilibre, ce qui est très utile pour chasser ou se faufiler discrètement.

Ce mode de déplacement, que l’on retrouve aussi chez les girafes ou les chameaux, s’appelle la marche en pas direct. C’est rare chez les animaux, et cela rend les chats encore plus fascinants.

Leur squelette et leurs muscles sont aussi conçus pour l’agilité : ils peuvent faire des bonds impressionnants, tourner rapidement en pleine course, et retomber sur leurs pattes grâce à un sens de l’équilibre exceptionnel.

Un arbre de décision, c’est une méthode utilisée pour prendre des décisions ou classer des choses. C’est un outil qu’on retrouve souvent en informatique, statistiques ou intelligence artificielle.

Comme son nom l’indique, il ressemble à un arbre, mais à l’envers :

    En haut, il y a le tronc, qu’on appelle la racine. C’est là qu’on commence.

    Ensuite, on suit des branches, qui correspondent à des questions ou des tests.

    À la fin de chaque chemin, on arrive à une feuille, qui donne une réponse ou une décision.

Un exemple concret :

Imaginons qu’on veut savoir si on doit prendre un parapluie. L’arbre de décision pourrait ressembler à ça :

    Est-ce qu’il pleut ?

        Oui → Prendre un parapluie.

        Non → Question suivante.

    Est-ce que le ciel est nuageux ?

        Oui → Prendre un parapluie par précaution.

        Non → Pas besoin de parapluie.

Chaque étape de l’arbre pose une question simple. À chaque réponse, on descend vers la suite, jusqu’à arriver à une décision.
Et en machine learning ?

En apprentissage automatique (machine learning), on utilise les arbres de décision pour apprendre à un programme à faire des choix. Par exemple, on peut lui apprendre à reconnaître si une image montre un chat ou un chien, en lui montrant plein d’exemples, et en construisant un arbre basé sur les caractéristiques (taille des oreilles, forme du museau, etc.).

Les bouteilles d’eau sont des objets que presque tout le monde utilise, souvent sans trop y penser. Qu’elles soient en plastique ou en verre, elles servent à contenir et transporter de l’eau potable, pour pouvoir s’hydrater facilement, que ce soit à la maison, au travail, à l’école ou en voyage.
D’où vient l’eau des bouteilles ?

L’eau en bouteille peut venir de différentes sources :

    Eau de source : elle provient directement d’une nappe souterraine et est embouteillée sans traitement chimique.

    Eau minérale naturelle : elle a une composition stable en minéraux et peut avoir des bienfaits spécifiques pour la santé.

    Eau purifiée : parfois, c’est de l’eau du robinet qui a été filtrée ou traitée.

Les types de bouteilles

    Bouteilles en plastique : légères, pratiques, mais elles posent des problèmes écologiques. Le plastique met longtemps à se dégrader et contribue à la pollution.

    Bouteilles en verre : plus écologiques car réutilisables et recyclables, mais plus lourdes et fragiles.

Et l’environnement ?

La production et l’usage massif de bouteilles en plastique ont un impact important sur l’environnement. Beaucoup ne sont pas recyclées et finissent dans la nature, notamment dans les océans. C’est pourquoi de plus en plus de gens utilisent des gourdes réutilisables ou des carafes filtrantes pour réduire leur consommation de plastique.


 - (similarity: 0.63) 16 to computer vision, was only 74.3%. Then in 2012, a team led by Alex Krizhevsky and advised by Geoffrey Hinton was able to achieve a top-5 accuracy of83.6%-a significant breakthrough. The competition has been dominated by deep convolutional neural networks every year since. By 2015, we had reached an accuracy of 96.4%, and the classification task on ImageNet was considered to be a completely solved problem. Since 2012, deep convolutional neural networks ("convnets") have become the go-to algorithm for all computer vision tasks, and generally all perceptual tasks. At major computer vision conferences in 2015 or 2016, it had become nearly impossible to find presentations that did not involve convnets in some form. At the same time, deep learning has also found applications in many other types of problems, such as natural language processing. It has come to completely replace SVMs and decision trees in a wide range of applications. For instance, for several years, the European Organization for Nuclear Research, CERN, used decision tree-based methods for analysis of particle data from the ATLAS detector at the Large Hadron Collider (LHC), but they eventually switched to Keras-based deep neural networks due to their higher performance and ease of training on large datasets. 1.2.6 What makes deep learning different The reason why deep learning took off SO quickly is primarily that it offered better performance on many problems. But that's not the only reason. Deep learning is also making problem-solving much easier, because it completely automates what used to be the most crucial step in a machine learning workflow: "feature engineering". Previous machine learning techniques, "shallow" learning, only involved transforming the input data into one or two successive representation spaces, usually via very simple transformations such as high-dimensional non-linear projections (SVM) or decision trees. But the refined representations required by complex problems generally cannot be attained by such techniques. As such, humans had to go to great length to make the initial input data more amenable to processing by these methods, i.e. they had to manually engineer good layers of representations for their data. This is what is called "feature engineering" Deep learning, on the other hand, completely automates this step: with deep learning, you learn all features in one pass rather than having to engineer them yourself. This has greatly simplified machine learning workflows, often replacing very sophisticated multi-stage pipelines with a single, simple, end-to-end deep learning model. You may ask, if the crux of the issue is to have multiple successive layers of representation, could shallow methods be applied repeatedly to emulate the effects of deep learning? In practice, there are fast-diminishing returns to successive application of shallow learning methods, because the optimal first representation layer in a 3-layer model is not the optimal first layer in a 1-layer or 2-layer model. What is transformative about deep learning is that it allows a model to learn all layers ofrepreseniation/oiuiy, at the same time, rather than in succession ("greedily", as it is called). With joint feature learning, whenever the model adjusts one of its internal features, all other features that depend on it will automatically adapt to the change, without requiring human OManning Publications Co. We welcome reader comments about anything in the manuscript other than typos and other simple mistakes. These will be cleaned up during production oft the book by copyeditors and proofreaders. htps/Horms.manping. comfiyums/dcp.i-aming-witb-python Licensed to <null>
 - (similarity: 0.58) 9 Input X Layer (data transformation) Layer (data transformation) Predictions Y'weights weights weight update True targets optimizer loss function loss score Figure 1.9 The loss score is used as a feedback signal to adjust the weights Initially, the weights of the network are assigned random values, SO the network merely implements a series of random transformations -naturally its output is very far from what it should ideally be, and the loss score is accordingly very high. But with every example that the network processes, the weights get adjusted just a little in the right direction, and the loss score decreases. This is the "training loop", which, repeated a sufficient number of times (typically tens of iterations overs thousands of examples), yields weight values that minimize the loss function. A network with a minimal loss is one for which the outputs are as close as they can be to the targets: a trained network. Once again: a very simple mechanism, which once scaled ends up looking like magic. Although deep learning is a fairly old subfield of machine learning, it only rose to prominence in the early 2010s. In the few years since, it has achieved nothing short of a revolution in the field, with remarkable results on all perceptual problems, such as "seeing" and "hearing". problems which involve skills that seem very natural and In particular, deep learning has achieved the following breakthroughs, all in 1.1.6 What deep learning has achieved so far intuitive to humans but have long been elusive for machines. historically difficult areas of machine learning: Near-human level image classification. Near-human level speech recognition. Near-human level handwriting transcription. Improved machine translation. Improved text-to-speech conversion. Digital assistants such as Google Now or Amazon Alexa. Near-human level autonomous driving. Improved ad targeting, as used by Google, Baidu, and Bing. Improved search results on the web. Answering natural language questions. Superhuman Go playing. In fact, we are still just exploring the full extent of what deep learning can do. We OManning Publications Co. We welcome reader comments about anything in the manuscript other than typos and other simple mistakes. These will be cleaned up during production oft the book by copyeditors and proofreaders. htps/Horms.manping. <EMAIL>-witb-python Licensed to <null>

 - (similarity: 0.48) Welcome Thank you for purchasing the MEAP for Deep Learning with Python. If you are looking for a resource to learn about deep learning from scratch and to quickly become able to use this knowledge to solve real-world problems, you have found the right book. *Deep Learning with Python* is meant for engineers and students with a reasonable amount of Python experience, but no significant knowledge of machine learning and deep learning. It will take you all the way from basic theory to advanced practical applications. However, if you already have experience with deep learning, you should still be able to find value in Deep learning is an immensely rich subfield of machine learning, with powerful applications ranging from machine perception to natural language processing, all the way up to creative AI. Yet, its core concepts are in fact very simple. Deep learning is often presented as shrouded in a certain mystique, with references to algorithms that work like the brain", that "think" or "understand". Reality is however quite far from this science fiction dream, and I will do my best in these pages to dispel these illusions. I believe that there are no difficult ideas in deep learning, and that's why I started this book, based on premise that all of the important concepts and applications in this field could be taught to This book is structured around a series of practical code examples, demonstrating on real world problems every the notions that gets introduced. I strongly believe in the value of teaching using concrete examples, anchoring theoretical ideas into actual results and tangible code patterns. These examples all rely on Keras, the Python deep learning library. When I released the initial version of Keras almost two years ago, little did I know that it would quickly skyrocket to become one of the most widely used deep learning frameworks. Al big part ofthat success is that Keras has always put ease of use and accessibility front and center. This same reason is what makes Keras a great library to get started with deep learning, and thus a great fit for this book. By the time you reach the end of this book, you Ih hope that you will this book valuable -deep learning will definitely open up new intellectual perspectives for you, and in fact it even has the potential to transform your career, being the most in-demand scientific specialization these days. I am looking forward to your reviews and comments. Your feedback is essential in order to write the best possible the latter chapters of this book. anyone, with very few prerequisites. will have become a Keras expert. book, that will benefit the greatest number of people. Francois Chollet OManning Publications Co. We welcome reader comments about anything in the manuscript other than typos and other simple mistakes. These will be cleaned up during production of the book by copyeditors and proofreaders. htps/forums.manping comfiyums/dcp.i-aming-witb-python Licensed to <null>

